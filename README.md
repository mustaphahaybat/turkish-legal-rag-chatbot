# ğŸ¤– Turkish Legal RAG Chatbot
### Retrieval Augmented Generation for Turkish Legal Education Documents
**TÃ¼rk Hukuk EÄŸitimi DokÃ¼manlarÄ± iÃ§in Geri Getirme GÃ¼Ã§lendirilmiÅŸ Ãœretim Sistemi**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—-Hugging%20Face-yellow.svg)](https://huggingface.co/)

---

## ğŸ¯ Project Overview | Proje Genel BakÄ±ÅŸ

A production-ready RAG (Retrieval Augmented Generation) chatbot specialized in Turkish legal education. This system processes legal documents, creates semantic embeddings, and generates contextually accurate answers by retrieving relevant information before generation.

**Turkish:** TÃ¼rk hukuk eÄŸitimi alanÄ±na Ã¶zel, Ã¼retime hazÄ±r bir RAG chatbot'u. Bu sistem hukuk dokÃ¼manlarÄ±nÄ± iÅŸler, semantik embedding'ler oluÅŸturur ve Ã¼retim Ã¶ncesinde ilgili bilgileri alarak baÄŸlamsal olarak doÄŸru cevaplar Ã¼retir.

---

## âœ¨ Key Features | Temel Ã–zellikler

- ğŸ‡¹ğŸ‡· **Turkish Language Optimization** - Specialized Turkish NLP models  
  *(TÃ¼rkÃ§e Dil Optimizasyonu - Ã–zel TÃ¼rkÃ§e NLP modelleri)*
  
- ğŸ“š **Intelligent Document Processing** - Smart chunking with overlap  
  *(AkÄ±llÄ± DokÃ¼man Ä°ÅŸleme - Ã–rtÃ¼ÅŸmeli akÄ±llÄ± parÃ§alama)*
  
- ğŸ” **Semantic Vector Search** - FAISS-powered similarity matching  
  *(Semantik VektÃ¶r AramasÄ± - FAISS destekli benzerlik eÅŸleÅŸtirme)*
  
- ğŸ¯ **Hallucination Detection** - Grounding score calculation  
  *(HalÃ¼sinasyon Tespiti - Temellendirme skoru hesaplama)*
  
- ğŸ“Š **Source Attribution** - Track answer origins  
  *(Kaynak AtÄ±fÄ± - Cevap kÃ¶kenlerini takip)*
  
- ğŸ’° **Zero Cost** - No API keys required, fully open-source  
  *(SÄ±fÄ±r Maliyet - API anahtarÄ± gerekmez, tamamen aÃ§Ä±k kaynak)*

---

## ğŸ—ï¸ Architecture | Mimari
```
User Question (KullanÄ±cÄ± Sorusu)
    â†“
Embedding Model (Turkish BERT - 768 dimensions)
    â†“
FAISS Vector Search (Cosine Similarity)
    â†“
Top-3 Chunks Retrieved (Context Building)
    â†“
Prompt = Context + Question
    â†“
LLM Generation (Turkish GPT-2)
    â†“
Grounded Answer + Source Attribution
```

**Why RAG? (Neden RAG?)**

Traditional LLMs hallucinate when asked about documents they haven't seen. RAG solves this by:
1. **Retrieval First** - Get actual document chunks
2. **Then Generate** - Use real context to produce answers
3. **Source Tracking** - Show where information came from

*Geleneksel LLM'ler gÃ¶rmediÄŸi dokÃ¼manlar hakkÄ±nda sorulduÄŸunda halÃ¼sinasyon yapar. RAG bunu ÅŸÃ¶yle Ã§Ã¶zer:*
1. *Ã–nce Getir - GerÃ§ek dokÃ¼man parÃ§alarÄ±nÄ± al*
2. *Sonra Ãœret - GerÃ§ek baÄŸlamÄ± kullanarak cevap oluÅŸtur*
3. *Kaynak Takibi - Bilginin nereden geldiÄŸini gÃ¶ster*

---

## ğŸ› ï¸ Tech Stack | Teknoloji YÄ±ÄŸÄ±nÄ±

### Models | Modeller
- **Embedding Model**: `emrecan/bert-base-turkish-cased-mean-nli-stsb-tr`
  - Turkish-optimized BERT (TÃ¼rkÃ§e optimize BERT)
  - 768-dimensional embeddings (768 boyutlu embedding'ler)
  - Semantic similarity search (Semantik benzerlik aramasÄ±)

- **LLM**: `ytu-ce-cosmos/turkish-gpt2-large`
  - Turkish GPT-2 Large (TÃ¼rkÃ§e GPT-2 BÃ¼yÃ¼k)
  - Text generation (Metin Ã¼retimi)
  - Domain-aware responses (Alan farkÄ±nda yanÄ±tlar)

### Libraries | KÃ¼tÃ¼phaneler

| Library | Version | Purpose |
|---------|---------|---------|
| **LangChain** | 0.1.0 | RAG framework |
| **FAISS** | 1.7.4 | Vector similarity search |
| **Transformers** | 4.36.0 | Hugging Face models |
| **Sentence Transformers** | 2.2.2 | Text embeddings |
| **PyPDF2** | 3.0.1 | PDF processing |
| **PyTorch** | 2.1.0 | Deep learning backend |

---

## ğŸš€ Quick Start | HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Prerequisites | Ã–n Gereksinimler
- Python 3.8+
- Google Colab (recommended) or local environment
- 8GB+ RAM (for model loading)

### Installation | Kurulum

**Option 1: Google Colab (Recommended)**
```python
# Open the notebook in Google Colab
# Run all cells sequentially
# No local setup needed!
```

**Option 2: Local Environment**
```bash
# Clone repository
git clone https://github.com/YOUR-USERNAME/turkish-legal-rag-chatbot.git
cd turkish-legal-rag-chatbot

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage | Temel KullanÄ±m
```python
from sentence_transformers import SentenceTransformer
import faiss
import pickle

# 1. Load embedding model
embedding_model = SentenceTransformer('emrecan/bert-base-turkish-cased-mean-nli-stsb-tr')

# 2. Load FAISS index (if you have the saved files)
index = faiss.read_index("data/faiss_index.bin")

# 3. Load chunks
with open('data/chunk_mapping.pkl', 'rb') as f:
    mapping = pickle.load(f)
    chunks = mapping['chunks']

# 4. Search function
def search(question, k=3):
    # Convert question to embedding
    q_embedding = embedding_model.encode([question]).astype('float32')
    
    # Search FAISS
    distances, indices = index.search(q_embedding, k)
    
    # Return relevant chunks
    results = [chunks[i] for i in indices[0]]
    return results

# 5. Ask a question!
question = "KarÅŸÄ±laÅŸtÄ±rmalÄ± hukukun rolÃ¼ nedir?"
context = search(question)
print(context)
```

---

## ğŸ“Š Performance Metrics | Performans Metrikleri

### Document Processing | DokÃ¼man Ä°ÅŸleme
| Metric | Value |
|--------|-------|
| **Total PDFs** | 3 documents |
| **Total Pages** | 58 pages |
| **Total Chunks** | ~150 chunks |
| **Chunk Size** | 1000 characters |
| **Chunk Overlap** | 200 characters |

### Embedding Performance | Embedding PerformansÄ±
| Metric | Value |
|--------|-------|
| **Model** | Turkish BERT |
| **Dimension** | 768 |
| **Total Embeddings** | ~150 vectors |
| **Memory Size** | ~1.2 MB |

### Retrieval Performance | Geri Getirme PerformansÄ±
| Metric | Value |
|--------|-------|
| **Index Type** | FAISS IndexFlatL2 (Exact) |
| **Search Method** | Cosine Similarity |
| **Avg Retrieval Time** | <50ms |
| **Top-k Results** | 3 chunks per query |

### Answer Quality | Cevap Kalitesi
| Metric | Value |
|--------|-------|
| **Grounding Score** | 60-80% |
| **Source Attribution** | 100% (always shown) |
| **Hallucination Rate** | Low (context-grounded) |

---

## ğŸ“š Source Documents | Kaynak DokÃ¼manlar

This chatbot was trained on 3 Turkish legal education documents:

1. **"Hukuk EÄŸitimindeki Son GeliÅŸmeler ve KarÅŸÄ±laÅŸtÄ±rmalÄ± Hukukun Hukuk EÄŸitimindeki RolÃ¼"**  
   - 40 pages
   - Topics: Legal education reforms, comparative law, European legal systems

2. **"Hukuk Biliminde GeliÅŸme"**  
   - 8 pages  
   - Topics: Legal epistemology, paradigm shifts, legal positivism

3. **"Hukuk AlanÄ±nda Ä°ÅŸbirliÄŸinin TÃ¼rk DÃ¼nyasÄ± AÃ§Ä±sÄ±ndan Ã–nemi"**  
   - 10 pages
   - Topics: Legal cooperation among Turkic states, judicial modernization

---

## ğŸ”¬ How It Works | NasÄ±l Ã‡alÄ±ÅŸÄ±r

### Step-by-Step Process | AdÄ±m AdÄ±m SÃ¼reÃ§

**1. Document Processing (DokÃ¼man Ä°ÅŸleme)**
- PDFs are read using PyPDF2
- Text extracted and cleaned
- Split into 1000-char chunks with 200-char overlap
- Each chunk stored with metadata

**2. Embedding Generation (Embedding OluÅŸturma)**
- Each chunk converted to 768-dim vector using Turkish BERT
- Embeddings capture semantic meaning
- Similar chunks have similar vectors

**3. Vector Storage (VektÃ¶r Depolama)**
- All embeddings stored in FAISS index
- IndexFlatL2 used for exact search
- Fast retrieval (<50ms)

**4. Query Processing (Sorgu Ä°ÅŸleme)**
- User question converted to embedding
- FAISS searches for top-3 similar chunks
- Chunks ranked by cosine similarity

**5. Answer Generation (Cevap Ãœretimi)**
- Retrieved chunks combined as context
- Prompt: "Context: ... Question: ... Answer:"
- Turkish GPT-2 generates grounded answer

**6. Quality Check (Kalite KontrolÃ¼)**
- Grounding score calculated
- Source attribution shown
- Hallucination detection applied

---

## ğŸ“ˆ Results & Validation | SonuÃ§lar ve DoÄŸrulama

### RAG vs Non-RAG Comparison

**Example Question:** "KarÅŸÄ±laÅŸtÄ±rmalÄ± hukukun rolÃ¼ nedir?"

| Aspect | RAG Answer | Non-RAG Answer |
|--------|------------|----------------|
| **Specificity** | Detailed, document-based | Generic, vague |
| **Accuracy** | High (from sources) | Variable (from training) |
| **Sources** | 3 documents cited | None |
| **Grounding** | 75% score | Not applicable |
| **Hallucination** | Low risk | High risk |

**Key Finding:** RAG answers are 60-80% grounded in source documents, significantly reducing hallucination compared to standalone LLM usage.

---

## ğŸ¯ Use Cases | KullanÄ±m AlanlarÄ±

### Current Applications | Mevcut Uygulamalar
- âœ… Legal education Q&A (Hukuk eÄŸitimi soru-cevap)
- âœ… Document-based research assistant (DokÃ¼man tabanlÄ± araÅŸtÄ±rma asistanÄ±)
- âœ… Turkish legal concept explanation (TÃ¼rk hukuk kavram aÃ§Ä±klamasÄ±)

### Potential Extensions | Potansiyel GeniÅŸletmeler
- ğŸ”œ Case law analysis (Vaka hukuku analizi)
- ğŸ”œ Legal document drafting assistance (Yasal belge taslaÄŸÄ± yardÄ±mÄ±)
- ğŸ”œ Multi-language support (Ã‡oklu dil desteÄŸi)

---

## ğŸ”® Future Improvements | Gelecek Ä°yileÅŸtirmeler

### Technical Enhancements | Teknik GeliÅŸtirmeler
- [ ] Multi-turn conversation support (Ã‡ok turlu konuÅŸma desteÄŸi)
- [ ] Query expansion techniques (Sorgu geniÅŸletme teknikleri)
- [ ] Re-ranking algorithms (Yeniden sÄ±ralama algoritmalarÄ±)
- [ ] Hybrid search (keyword + semantic) (Hibrit arama)

### Model Improvements | Model Ä°yileÅŸtirmeleri
- [ ] Fine-tune on legal corpus (Hukuk korpusu Ã¼zerinde ince ayar)
- [ ] Larger context windows (Daha bÃ¼yÃ¼k baÄŸlam pencereleri)
- [ ] Better Turkish LLM integration (Daha iyi TÃ¼rkÃ§e LLM entegrasyonu)

### Content Expansion | Ä°Ã§erik GeniÅŸletme
- [ ] Add more legal documents (Daha fazla hukuk dokÃ¼manÄ± ekleme)
- [ ] Include case law (Vaka hukuku dahil etme)
- [ ] Multi-domain support (Ã‡ok alanlÄ± destek)

---

## ğŸ‘¨â€ğŸ’» Author | Yazar

**Mustafa Haybat GÃ¶zgÃ¶z**

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=flat&logo=linkedin)](https://www.linkedin.com/in/mustafa-haybat-gozgoz35)

**Background (GeÃ§miÅŸ):**  
Former legal professional transitioning to AI/ML engineering. This project combines domain expertise in Turkish law with modern NLP techniques.

*Eski hukuk profesyonelinden AI/ML mÃ¼hendisliÄŸine geÃ§iÅŸ yapÄ±yor. Bu proje, TÃ¼rk hukuku alanÄ±ndaki uzmanlÄ±ÄŸÄ± modern NLP teknikleriyle birleÅŸtiriyor.*

**Why This Project? (Neden Bu Proje?):**  
Having worked in the legal field, I understand the challenges of information retrieval in specialized domains. RAG technology bridges the gap between legal expertise and AI capabilities.

---

## ğŸ“„ License | Lisans

MIT License - Free to use for educational and commercial purposes.

---

## ğŸ™ Acknowledgments | TeÅŸekkÃ¼rler

- **Hugging Face** - Turkish NLP models
- **Meta AI** - FAISS vector search library
- **LangChain** - RAG framework
- **Turkish NLP Community** - Open-source models and support

---

## ğŸ“ Contact & Collaboration | Ä°letiÅŸim ve Ä°ÅŸbirliÄŸi

Interested in:
- RAG systems for specialized domains?
- Turkish NLP applications?
- Legal tech innovation?
- Collaboration opportunities?

**Let's connect!** (BaÄŸlantÄ± kuralÄ±m!)

ğŸ’¼ LinkedIn: [linkedin.com/in/mustafa-haybat-gozgoz35](https://www.linkedin.com/in/mustafa-haybat-gozgoz35)

---

## ğŸŒŸ Star This Project! | Bu Projeye YÄ±ldÄ±z Ver!

If you find this project useful, please star the repository!

*Bu projeyi faydalÄ± bulduysanÄ±z, lÃ¼tfen repository'ye yÄ±ldÄ±z verin!*

---

**Built with â¤ï¸ and Turkish NLP**  
*TÃ¼rkÃ§e NLP ile â¤ï¸ ile yapÄ±ldÄ±*
